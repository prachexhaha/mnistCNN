{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# Define the CNN model\n",
    "model = Sequential()\n",
    "\n",
    "# First Convolutional Layer\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "\n",
    "# Second Convolutional Layer\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "\n",
    "# Max Pooling Layer\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten layer to convert 2D feature maps to 1D feature vectors\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully Connected Layer\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "# Dropout Layer\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Output Layer\n",
    "model.add(Dense(26, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model: \"sequential\"\n",
    "_________________________________________________________________\n",
    " Layer (type)                Output Shape              Param #   \n",
    "=================================================================\n",
    " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
    "                                                                 \n",
    " conv2d_1 (Conv2D)           (None, 24, 24, 64)        18496     \n",
    "                                                                 \n",
    " max_pooling2d (MaxPooling2  (None, 12, 12, 64)        0         \n",
    " D)                                                              \n",
    "                                                                 \n",
    " flatten (Flatten)           (None, 9216)              0         \n",
    "                                                                 \n",
    " dense (Dense)               (None, 128)               1179776   \n",
    "                                                                 \n",
    " dropout (Dropout)           (None, 128)               0         \n",
    "                                                                 \n",
    " dense_1 (Dense)             (None, 26)                3354      \n",
    "                                                                 \n",
    "=================================================================\n",
    "Total params: 1201946 (4.59 MB)\n",
    "Trainable params: 1201946 (4.59 MB)\n",
    "Non-trainable params: 0 (0.00 Byte)\n",
    "_________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "import pydot\n",
    "\n",
    "# Visualize the model architecture\n",
    "plot_model(model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, load_img\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "train_df = pd.read_csv('/content/drive/MyDrive/ML_Assignment/Mini_Project/sign_mnist_train.csv')\n",
    "test_df = pd.read_csv('/content/drive/MyDrive/ML_Assignment/Mini_Project/sign_mnist_test.csv')\n",
    "\n",
    "X_train, y_train = np.array(train_df.iloc[:, 1:]).reshape(-1, 28, 28).astype('float64'), np.array(train_df.label).astype('float64')\n",
    "X_test, y_test = np.array(test_df.iloc[:, 1:]).reshape(-1, 28, 28).astype('float64'), np.array(test_df.label).astype('float64')\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(27455, 28, 28) (27455,)\n",
    "(7172, 28, 28) (7172,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1.0/255.0,\n",
    "                                  zoom_range=0.2,\n",
    "                                  width_shift_range=0.2,\n",
    "                                  height_shift_range=0.2)\n",
    "\n",
    "train_generator = train_datagen.flow(x=np.expand_dims(X_train, axis=-1), y=y_train,\n",
    "                  batch_size=32)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "test_generator = test_datagen.flow(x=np.expand_dims(X_test, axis=-1), y=y_test,\n",
    "                  batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a sample of 10 images from the training set\n",
    "def plot_categories(training_images, training_labels):\n",
    "  fig, axes = plt.subplots(1, 10, figsize=(16, 15))\n",
    "  axes = axes.flatten()\n",
    "  letters = list(string.ascii_lowercase)\n",
    "\n",
    "  for k in range(10):\n",
    "    img = training_images[k]\n",
    "    img = np.expand_dims(img, axis=-1)\n",
    "    img = array_to_img(img)\n",
    "    ax = axes[k]\n",
    "    ax.imshow(img, cmap=\"Greys_r\")\n",
    "    ax.set_title(f\"{letters[int(training_labels[k])]}\")\n",
    "    ax.set_axis_off()\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.show()\n",
    "\n",
    "plot_categories(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "history = model.fit(train_generator, validation_data=test_generator, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Success Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 3))\n",
    "ax = ax.ravel()\n",
    "\n",
    "for i, met in enumerate(['accuracy', 'loss']):\n",
    "    ax[i].plot(history.history[met])\n",
    "    ax[i].plot(history.history['val_' + met])\n",
    "    ax[i].set_title('Model {}'.format(met))\n",
    "    ax[i].set_xlabel('epochs')\n",
    "    ax[i].set_ylabel(met)\n",
    "    ax[i].legend(['train', 'val'])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
